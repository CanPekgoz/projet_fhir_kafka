# Projet Streaming de Donn√©es M√©dicales (FHIR + Kafka + Elastic)

## Fonctionnement d√©taill√© du syst√®me

Le projet impl√©mente une cha√Æne compl√®te de traitement de donn√©es m√©dicales en temps r√©el bas√©e sur une architecture Big Data.  
L‚Äôobjectif est de simuler la surveillance continue de la pression art√©rielle de patients et de d√©tecter automatiquement les anomalies.

Le pipeline suit les √©tapes suivantes :

Patient ‚Üí G√©n√©ration FHIR ‚Üí Kafka ‚Üí Analyse ‚Üí Elasticsearch ‚Üí Kibana

### 1. G√©n√©ration des donn√©es m√©dicales (FHIR)

Un module Python simule des patients et g√©n√®re des mesures de pression art√©rielle :
- Pression systolique
- Pression diastolique

Chaque mesure est encod√©e au format standard m√©dical **FHIR (Fast Healthcare Interoperability Resources)** sous forme de ressource *Observation*.

Ce standard est utilis√© dans les syst√®mes hospitaliers r√©els car il permet l‚Äôinterop√©rabilit√© entre logiciels m√©dicaux.

Les donn√©es produites repr√©sentent donc des observations m√©dicales r√©alistes et structur√©es.

---

### 2. Streaming temps r√©el avec Kafka

Les observations FHIR sont envoy√©es dans un topic Kafka par un Producer Python.

Kafka agit comme un syst√®me de transport de donn√©es en continu :
- il re√ßoit les mesures
- les stocke temporairement
- les distribue aux applications consommatrices

Cette √©tape simule un capteur m√©dical connect√© qui envoie les donn√©es en continu depuis un h√¥pital ou un dispositif IoT.

Le streaming permet de traiter les donn√©es imm√©diatement sans attendre un traitement batch.

---

### 3. Consommation et analyse m√©dicale

Un Consumer Python lit les messages depuis Kafka et effectue une analyse clinique.

Les r√®gles m√©dicales utilis√©es sont bas√©es sur des seuils r√©els :

| Type | Condition |
|----|----|
| Hypotension | systolique < 90 ou diastolique < 60 |
| Hypertension | systolique > 140 ou diastolique > 90 |

Chaque observation est class√©e :

- **Normale**
- **Anormale (anomalie d√©tect√©e)**

Cette √©tape repr√©sente un syst√®me d‚Äôaide √† la d√©cision m√©dicale automatis√©.


### 4. Traitement des r√©sultats

Selon le r√©sultat de l‚Äôanalyse :

#### Cas normal
Les donn√©es sont archiv√©es localement en fichier JSON.
Cela simule un stockage patient standard sans alerte m√©dicale.

#### Cas anormal
Les donn√©es sont envoy√©es vers Elasticsearch avec des m√©tadonn√©es :
- valeur systolique
- valeur diastolique
- type d‚Äôanomalie
- timestamp

Cela repr√©sente un cas n√©cessitant une surveillance m√©dicale.

### 5. Indexation dans Elasticsearch

Elasticsearch sert de base de donn√©es orient√©e recherche.

Il permet :
- stockage rapide
- requ√™tes temps r√©el
- agr√©gations statistiques

Chaque anomalie devient un document index√© consultable imm√©diatement.

### 6. Visualisation dans Kibana

Kibana permet d‚Äôexploiter les donn√©es index√©es pour la supervision m√©dicale.

Les tableaux de bord affichent :

- √©volution temporelle des anomalies
- distribution des pressions art√©rielles
- taux d‚Äôanomalies
- d√©tection de pics critiques

Le syst√®me devient alors un tableau de monitoring patient en temps r√©el.

## Fonctionnement global

Le projet simule un syst√®me hospitalier moderne :

1. Capteurs m√©dicaux ‚Üí g√©n√®rent les mesures
2. Kafka ‚Üí transporte les donn√©es en continu
3. Analyse Python ‚Üí d√©tecte les anomalies
4. Elasticsearch ‚Üí stocke les cas critiques
5. Kibana ‚Üí permet au personnel m√©dical de surveiller

Cette architecture correspond aux syst√®mes de t√©l√©surveillance m√©dicale utilis√©s dans les h√¥pitaux connect√©s.

Le traitement se fait en continu et permet de d√©tecter rapidement les situation a des riques.

## Architecture

## üèóÔ∏è Architecture du syst√®me
![Architecture](screenshots/Architecture.png)

Python Generator ‚Üí Kafka ‚Üí Python Consumer ‚Üí Elasticsearch ‚Üí Kibana

Ce pipeline reproduit un syst√®me de surveillance m√©dicale continu (monitoring patient)

##  R√©sultats et preuves d‚Äôex√©cution

###  Infrastructure Docker lanc√©e
![Docker](screenshots/Docker_running.png)

###  Containers actifs dans Docker Desktop
![Docker Panel](screenshots/Docker_Pannel.png)

###  Producer envoi des donn√©es
![Producer](screenshots/Consumer_Producer.png)

###  D√©tection d‚Äôanomalies + envoi Elasticsearch
![Anomalies](screenshots/Hits_anomalies.png)

###  Donn√©es stock√©es dans Elasticsearch
![Index](screenshots/Kibana_index.png)

###  Dashboard Kibana temps r√©el
![Dashboard](screenshots/Kibana_Dashboard.png)

## Donn√©es trait√©es

* Systolique
* Diastolique
* D√©tection d'anomalies tension art√©rielle

## Technologies

* Python
* Kafka
* Elasticsearch
* Kibana
* Docker
* FHIR

## Description
G√©n√©ration de messages FHIR (Observation - pression art√©rielle), envoi dans Kafka, d√©tection d‚Äôanomalies, stockage dans Elasticsearch et visualisation dans Kibana.

## Pr√©requis
- Docker Desktop
- Python 3.11+
- pip

## Installation Python
```bash
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt

## üîÅ Reproductibilit√©

Le projet peut √™tre relanc√© enti√®rement avec Docker.

### 1. Installer les d√©pendances Python
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt

### 2. Lancer l‚Äôinfrastructure
cd docker
docker compose up -d

### 3. Lancer le pipeline
python -m consumer.consumer
python -m producer.producer

### 4. Ouvrir la visualisation
http://localhost:5601


## Technologies utilis√©es et r√¥le dans l‚Äôarchitecture

Le projet repose sur une architecture distribu√©e compos√©e de plusieurs outils Big Data sp√©cialis√©s.  
Chaque composant a un r√¥le pr√©cis dans la cha√Æne de traitement.

---

### FHIR (Fast Healthcare Interoperability Resources)

FHIR est un standard international utilis√© dans les syst√®mes m√©dicaux pour √©changer des donn√©es de sant√©.

Dans ce projet, il sert √† :
- structurer les observations m√©dicales
- rendre les donn√©es interop√©rables
- simuler un syst√®me hospitalier r√©el

La ressource utilis√©e est **Observation**, qui permet de repr√©senter une mesure m√©dicale comme la pression art√©rielle.

L‚Äôutilisation de FHIR permet de rendre le projet r√©aliste et compatible avec les logiciels hospitaliers modernes.

---

### Apache Kafka

Kafka est une plateforme de streaming distribu√©e utilis√©e pour transporter des donn√©es en temps r√©el.

Dans le projet, Kafka joue le r√¥le de bus de communication :

- le Producer envoie les observations m√©dicales
- le Consumer les r√©cup√®re imm√©diatement

Avantages apport√©s :
- traitement temps r√©el
- d√©couplage des services
- scalabilit√©
- tol√©rance aux pannes

Kafka simule un flux continu provenant de capteurs m√©dicaux connect√©s.

---

### Python

Python est utilis√© pour impl√©menter la logique m√©tier du syst√®me :

- g√©n√©ration de donn√©es patients
- conversion en format FHIR
- publication dans Kafka
- analyse clinique
- d√©tection d‚Äôanomalies
- envoi vers Elasticsearch

Il agit donc comme moteur d‚Äôintelligence du syst√®me.

---

### Elasticsearch

Elasticsearch est une base de donn√©es orient√©e recherche optimis√©e pour les donn√©es volumineuses et temps r√©el.

Dans le projet il sert √† :

- stocker uniquement les cas anormaux
- permettre des recherches rapides
- agr√©ger les statistiques m√©dicales
- pr√©parer les donn√©es pour la visualisation

Il repr√©sente la base de surveillance m√©dicale.

---

### Kibana

Kibana est l‚Äôoutil de visualisation connect√© √† Elasticsearch.

Il permet :

- cr√©er des tableaux de bord m√©dicaux
- suivre les patients √† risque
- visualiser les tendances
- d√©tecter les pics critiques

C‚Äôest l‚Äôinterface utilisateur finale du syst√®me.

---

### Docker

Docker permet d‚Äôex√©cuter toute l‚Äôinfrastructure sans installation complexe.

Il garantit :

- reproductibilit√© du projet
- d√©ploiement simple
- environnement identique sur toutes les machines

Les services lanc√©s par Docker Compose :
- Zookeeper
- Kafka
- Elasticsearch
- Kibana

Un simple `docker compose up` permet de d√©marrer toute la plateforme.

---

## R√©sum√© de l‚Äôarchitecture

| Composant | R√¥le |
|--------|------|
| FHIR | Standard m√©dical des donn√©es |
| Python | Logique et analyse |
| Kafka | Transport temps r√©el |
| Elasticsearch | Stockage des anomalies |
| Kibana | Visualisation |
| Docker | Reproductibilit√© |

## Conclusion

Ce projet met en place une cha√Æne compl√®te de traitement de donn√©es m√©dicales en temps r√©el.

Nous avons construit une architecture Big Data permettant :

- la g√©n√©ration de donn√©es patients au format FHIR
- la transmission continue via Kafka
- l‚Äôanalyse clinique automatis√©e
- la d√©tection d‚Äôanomalies m√©dicales
- le stockage cibl√© des cas critiques
- la visualisation interactive dans Kibana

Le syst√®me reproduit le fonctionnement d‚Äôune plateforme de t√©l√©surveillance m√©dicale o√π des capteurs envoient en continu les constantes vitales des patients.

L‚Äôutilisation de technologies distribu√©es permet d‚Äôassurer :
- rapidit√© de traitement
- fiabilit√©
- extensibilit√©
- surveillance en temps r√©el

Ainsi, ce projet d√©montre concr√®tement comment une architecture Big Data peut √™tre appliqu√©e au domaine de la sant√© pour am√©liorer le suivi des patients.

---

## Limites actuelles

Le syst√®me repose actuellement sur des seuils m√©dicaux fixes pour d√©tecter les anomalies.  
Cela fonctionne mais reste limit√© car tous les patients sont analys√©s de la m√™me mani√®re.

Un patient sportif ou √¢g√© peut avoir des valeurs normales diff√©rentes.

---

## Am√©lioration possible : Machine Learning (optionnel)

Une am√©lioration consiste √† ajouter un mod√®le de Machine Learning capable d‚Äôapprendre les comportements normaux d‚Äôun patient.

Principe :

1. Collecter un historique de mesures
2. Entra√Æner un mod√®le de classification (ex : r√©gression logistique)
3. Pr√©dire le risque en temps r√©el dans le consumer Kafka

Le syst√®me passerait alors d‚Äôune d√©tection par r√®gles √† une d√©tection intelligente personnalis√©e.

Cela permettrait :
- moins de faux positifs
- d√©tection pr√©coce
- adaptation au patient

---

## Reproductibilit√©

Le projet est enti√®rement reproductible gr√¢ce √† Docker.

Pour relancer le syst√®me sur une nouvelle machine :

git clone https://github.com/CanPekgoz/projet_fhir_kafka.git
cd projet_fhir_kafka

# cr√©er venv
python -m venv .venv
.\.venv\Scripts\activate

# installer d√©pendances
pip install -r requirements.txt

# d√©marrer l‚Äôinfra
cd docker
docker compose up -d
cd ..

# lancer consumer
python -m consumer.consumer

# lancer producer (dans un 2e terminal)
python -m producer.producer

Et ajoute les URLs :
	‚Ä¢	Kibana : http://localhost:5601
	‚Ä¢	Elasticsearch : http://localhost:9200
